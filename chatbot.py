import faiss
import json
import numpy as np
from datetime import datetime, timedelta
from sentence_transformers import SentenceTransformer
import re

class ScopusChatbot:
    def __init__(self, index_path="arxiv_index.faiss", metadata_path="arxiv_metadata.json"):
        self.model = SentenceTransformer("all-MiniLM-L6-v2")
        self.index = faiss.read_index(index_path)
        with open(metadata_path, "r", encoding="utf-8") as f:
            self.metadata = json.load(f)
        
        # Dictionnaire des mots-cl√©s pour diff√©rents types de requ√™tes
        self.keywords = {
            "recent_articles": {
                "fr": ["articles r√©cents", "publications r√©centes", "nouveaux articles", "derniers travaux", 
                       "r√©cent", "nouveau", "derni√®re publication", "actualit√©s scientifiques", "publications actuelles", "travaux r√©cents"],
                "en": ["recent articles", "latest publications", "new articles", "recent works", 
                       "recent", "new", "latest", "current research", "fresh publications", "newest papers"]
            },
            "author_search": {
                "fr": ["travaux de", "publications de", "articles de", "recherches de", "auteur", 
                       "chercheur", "scientifique", "professeur", "≈ìuvres de", "√©tudes de"],
                "en": ["works by", "publications by", "articles by", "research by", "author", 
                       "researcher", "scientist", "professor", "studies by", "papers by"]
            },
            "statistics": {
                "fr": ["statistiques", "nombre d'articles", "total articles", "comptage", "donn√©es", 
                       "chiffres", "m√©triques", "quantit√©", "volume", "nombre total"],
                "en": ["statistics", "number of articles", "total articles", "count", "data", 
                       "figures", "metrics", "quantity", "volume", "total number"]
            },
            "ai_medicine": {
                "fr": ["intelligence artificielle", "m√©decine", "sant√©", "diagnostic", "traitement", 
                       "IA m√©dicale", "algorithmes m√©dicaux", "apprentissage automatique", "deep learning", "machine learning"],
                "en": ["artificial intelligence", "medicine", "health", "diagnosis", "treatment", 
                       "medical AI", "medical algorithms", "machine learning", "deep learning", "healthcare AI"]
            },
            "computer_science": {
                "fr": ["informatique", "programmation", "algorithmes", "logiciel", "syst√®me", 
                       "ordinateur", "technologie", "code", "d√©veloppement", "ing√©nierie"],
                "en": ["computer science", "programming", "algorithms", "software", "system", 
                       "computer", "technology", "code", "development", "engineering"]
            },
            "biology": {
                "fr": ["biologie", "g√©n√©tique", "cellule", "organisme", "√©volution", 
                       "biochimie", "biotechnologie", "microbiologie", "physiologie", "√©cologie"],
                "en": ["biology", "genetics", "cell", "organism", "evolution", 
                       "biochemistry", "biotechnology", "microbiology", "physiology", "ecology"]
            },
            "physics": {
                "fr": ["physique", "quantique", "particule", "√©nergie", "mati√®re", 
                       "th√©orie", "exp√©rience", "m√©canique", "thermodynamique", "optique"],
                "en": ["physics", "quantum", "particle", "energy", "matter", 
                       "theory", "experiment", "mechanics", "thermodynamics", "optics"]
            },
            "chemistry": {
                "fr": ["chimie", "mol√©cule", "r√©action", "compos√©", "synth√®se", 
                       "catalyse", "organique", "inorganique", "analytique", "physico-chimie"],
                "en": ["chemistry", "molecule", "reaction", "compound", "synthesis", 
                       "catalysis", "organic", "inorganic", "analytical", "physical chemistry"]
            }
        }

    def extract_keywords_from_query(self, query):
        """Extrait et sugg√®re des mots-cl√©s bas√©s sur la requ√™te"""
        query_lower = query.lower()
        detected_keywords = []
        
        for category, keywords in self.keywords.items():
            for lang in ["fr", "en"]:
                for keyword in keywords[lang]:
                    if keyword in query_lower:
                        detected_keywords.extend(keywords[lang][:5])  # Prendre les 5 premiers
                        break
                if detected_keywords:
                    break
        
        return list(set(detected_keywords))

    def enhance_query_with_keywords(self, query):
        """Am√©liore la requ√™te avec des mots-cl√©s pertinents"""
        base_keywords = self.extract_keywords_from_query(query)
        
        if len(base_keywords) < 10:
            generic_keywords = [
                "research", "study", "analysis", "investigation", "publication",
                "recherche", "√©tude", "analyse", "investigation", "publication"
            ]
            base_keywords.extend(generic_keywords[:10-len(base_keywords)])
        
        return base_keywords[:10]

    def process_query(self, query):
        """Traite la requ√™te avec am√©lioration par mots-cl√©s"""
        query = query.lower()
        keywords = self.enhance_query_with_keywords(query)
        
        print(f"üîç Mots-cl√©s d√©tect√©s: {', '.join(keywords)}")
        
        recent_patterns = ["articles r√©cents", "recent articles", "publications r√©centes", "latest publications"]
        if any(pattern in query for pattern in recent_patterns):
            return self.get_recent_articles(), keywords

        author_patterns = ["travaux de", "works by", "publications de", "articles de", "research by"]
        for pattern in author_patterns:
            if pattern in query:
                name = query.split(pattern)[-1].strip()
                return self.get_articles_by_author(name), keywords

        stats_patterns = ["statistiques", "statistics", "nombre d'articles", "number of articles", "total articles"]
        if any(pattern in query for pattern in stats_patterns):
            return self.get_stats(), keywords

        enhanced_query = query + " " + " ".join(keywords)
        return self.semantic_search(enhanced_query), keywords

    def semantic_search(self, query, k=5):
        """Recherche s√©mantique am√©lior√©e"""
        q_emb = self.model.encode([query])
        _, I = self.index.search(np.array(q_emb).astype("float32"), k)
        return [self.metadata[i] for i in I[0] if i < len(self.metadata)]

    def get_articles_by_author(self, name):
        """Recherche d'articles par auteur avec recherche flexible"""
        name = name.lower().strip()
        result = []
        
        for art in self.metadata:
            authors = art.get("authors", [])
            for author in authors:
                author_name = author.get("name", "").lower()
                if name in author_name or any(part in author_name for part in name.split()):
                    result.append(art)
                    break
        
        return result

    def get_recent_articles(self, days=30):
        """R√©cup√®re les articles r√©cents avec gestion d'erreurs"""
        cutoff = datetime.now() - timedelta(days=days)
        recent_articles = []
        
        for article in self.metadata:
            if "published_date" in article:
                try:
                    pub_date = datetime.strptime(article["published_date"], "%Y-%m-%d")
                    if pub_date >= cutoff:
                        recent_articles.append(article)
                except ValueError:
                    continue
        
        return recent_articles

    def get_stats(self):
        """Statistiques d√©taill√©es"""
        author_names = set()
        categories = {}
        years = {}
        
        for art in self.metadata:
            for a in art.get("authors", []):
                if isinstance(a, dict) and "name" in a:
                    author_names.add(a["name"])
            
            category = art.get("category", "Unknown")
            categories[category] = categories.get(category, 0) + 1
            
            if "published_date" in art:
                try:
                    year = datetime.strptime(art["published_date"], "%Y-%m-%d").year
                    years[year] = years.get(year, 0) + 1
                except ValueError:
                    pass
        
        return {
            "total_articles": len(self.metadata),
            "authors_count": len(author_names),
            "categories": categories,
            "years": years
        }

    def search_by_topic(self, topic):
        """Recherche par sujet avec mots-cl√©s √©tendus"""
        topic_keywords = self.enhance_query_with_keywords(topic)
        enhanced_query = topic + " " + " ".join(topic_keywords)
        return self.semantic_search(enhanced_query)

    def get_trending_topics(self):
        """Identifie les sujets tendance bas√©s sur les mots-cl√©s"""
        word_freq = {}
        
        for art in self.metadata:
            title = art.get("title", "").lower()
            abstract = art.get("abstract", "").lower()
            
            words = re.findall(r'\b\w+\b', title + " " + abstract)
            for word in words:
                if len(word) > 4:
                    word_freq[word] = word_freq.get(word, 0) + 1
        
        return sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:20]

    def get_articles_about_keyword(self, keyword):
        """Retourne les articles contenant un mot-cl√© dans le titre ou r√©sum√©"""
        keyword = keyword.lower()
        results = []
        for art in self.metadata:
            title = art.get("title", "").lower()
            abstract = art.get("abstract", "").lower()
            if keyword in title or keyword in abstract:
                results.append(art)
        return results

def main():
    try:
        chatbot = ScopusChatbot()

        print("üîç R√©sultat recherche s√©mantique am√©lior√©e :")
        result, keywords = chatbot.process_query("intelligence artificielle et m√©decine")
        print(f"Mots-cl√©s utilis√©s: {keywords}")
        for article in result[:3]:
            print(f"- {article.get('title', 'Titre non disponible')}")

        print("\nüìÖ Articles publi√©s r√©cemment :")
        recent_articles, keywords = chatbot.process_query("articles r√©cents")
        print(f"Mots-cl√©s utilis√©s: {keywords}")
        for article in recent_articles[:3]:
            print(f"- {article.get('title', 'Titre non disponible')} ({article.get('published_date', '?')})")

        print("\nüë®‚Äçüî¨ Travaux de 'Helen Qu' :")
        works, keywords = chatbot.process_query("travaux de Helen Qu")
        print(f"Mots-cl√©s utilis√©s: {keywords}")
        for article in works[:3]:
            print(f"- {article.get('title', 'Titre non disponible')}")

        print("\nüìä Statistiques :")
        stats, keywords = chatbot.process_query("statistiques")
        print(f"Mots-cl√©s utilis√©s: {keywords}")
        print(f"- Nombre total d'articles : {stats['total_articles']}")
        print(f"- Nombre d'auteurs uniques : {stats['authors_count']}")

        print("\nüî• Sujets tendance :")
        trending = chatbot.get_trending_topics()
        for word, freq in trending[:10]:
            print(f"- {word}: {freq} occurrences")

        # Nouveaut√© : articles sur "machine learning"
        print("\nüìö Articles sur 'machine learning' :")
        ml_articles = chatbot.get_articles_about_keyword("machine learning")
        seen_titles = set()
        for article in ml_articles[:10]:
            title = article.get('title', 'Titre inconnu')
            if title not in seen_titles:
                print(f"- {title} ({article.get('published_date', '?')})")
                seen_titles.add(title)

        print("\nüß† Tests de requ√™tes vari√©es :")
        test_queries = [
            "deep learning et biologie",
            "quantum computing",
            "machine learning applications",
            "recherche en informatique",
            "intelligence artificielle m√©dicale",
            "publications en chimie",
            "physique quantique",
            "biotechnologie moderne"
        ]
        
        for query in test_queries:
            print(f"\nüîé Requ√™te : {query}")
            result, keywords = chatbot.process_query(query)
            print(f"Mots-cl√©s: {', '.join(keywords)}")
            if isinstance(result, list):
                print(f"R√©sultats trouv√©s: {len(result)}")
                for art in result[:2]:
                    print(f"- {art.get('title', 'Titre inconnu')}")
            else:
                print(result)

    except FileNotFoundError as e:
        print(f"‚ùå Fichier manquant : {e}")
        print("üí° Assurez-vous que les fichiers arxiv_index.faiss et arxiv_metadata.json existent")
    except json.JSONDecodeError as e:
        print(f"‚ùå Erreur de lecture du JSON : {e}")
    except Exception as e:
        print(f"‚ùå Une erreur inattendue est survenue : {e}")

if __name__ == "__main__":
    main()
